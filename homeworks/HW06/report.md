HW06 – Report

    Файл: homeworks/HW06/report.md
    Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

1. Dataset

    Какой датасет выбран: S06-hw-dataset-04.csv
    Размер: (25000, 62)
    Целевая переменная: target (два класса: 0, 1; доли - 0: 0.9508, 1: 0.0492)
    Признаки: только числовые (float64: 60, int64: 2)

2. Protocol

    Разбиение: train/test = 75% / 25%, random_state = 5
    Для сохранения долей классов использовалась стратификация по целевой переменной (stratify = y)
    Выбор модели: Кросс-валидация: 5-кратная стратифицированная KFold на обучающем наборе Метрика оценки: ROC-AUC (из-за дисбаланса классов; приоритет ранжирования над абсолютным пороговым значением) Метрики оценки (на тестовом наборе): Точность: общая правильность (базовая релевантность) F1-показатель: гармоническое среднее точности/восстановления (полезно для классов меньшинства) ROC-AUC: качество ранжирования по порогам (устойчивость к дисбалансу) Средняя точность (PR-AUC): дополнение к ROC-AUC при дисбалансе Метрики качества:
    accuracy — базовая метрика
    F1-score — учитывает дисбаланс классов
    ROC-AUC — основная метрика выбора модели, так как отражает качество ранжирования и устойчива к дисбалансу классов

3. Models

В работе были реализованы и сравнены следующие модели:

    DummyClassifier (most_frequent) - наивный baseline
    LogisticRegression - использовалась через Pipeline(StandardScaler → LogisticRegression) max_iter=2000, масштабированные характеристики
    DecisionTree - контроль сложности осуществлялся с помощью max_depth и min_samples_leaf
    RandomForestClassifier - подбирались параметры: n_estimators, max_depth, min_samples_leaf, max_features
    HistGradientBoosting - подбирались параметры: learning_rate, max_depth, max_iter, min_samples_leaf

Для всех моделей с подбором гиперпараметров использовался GridSearchCV с кросс-валидацией на train-выборке. Все неленейные модели использовали настройки по умолчанию, если это не указано в сетке.
4. Results
Финальные метрики на test-выборке
| Модель                   | Accuracy | F1-score | ROC-AUC  |
|--------------------------|----------|----------|----------|
| DummyClassifier          | 0.95072  | 0.000000 | 0.500000 |
| LogisticRegression       | 0.96240  | 0.395887 | 0.858707 |
| DecisionTree             | 0.96176  | 0.507216 | 0.808333 |
| RandomForest             | 0.96880  | 0.539007 | 0.891053 |
| HistGradientBoosting     | 0.97680  | 0.694737 | 0.903436 |

Победитель: HistGradientBoosting  
Наивысшие показатели ROC-AUC, F1 и точности. Лучший баланс между обнаружением меньшинства классов и общей производительностью. Превосходит даже настроенные ансамбли деревьев, такие как Random Forest.

5. Analysis

Стабильность (5 семян: 11, 22, 33, 44, 55)  
Оценены LogisticRegression и HistGradientBoosting. HistGradientBoosting продемонстрировал низкую дисперсию:  
ROC-AUC std: 0.0038  
F1 std: 0.0114  
LogisticRegression немного менее стабилен, но все же остается последовательным. Сделан вывод о надежности градиентного бустинга при повторной выборке.  

Матрица путаницы (лучшая модель)  
Высокий показатель истинных отрицательных результатов (как и ожидалось, учитывая смещение классов)  
Восстановление для класса 1: ~60–65% (хорошо, учитывая дисбаланс)  
Точность для класса 1: ~50–55%  
Компромисс приемлем для обнаружения высоких ставок, где важно восстановление  

Важность перестановки (топ-15)  
Лучшие характеристики по влиянию на ROC-AUC при перестановке:  
f54, f23, f17, f39, f45, f11, f51, f03, f29, f07  
Характеристики не интерпретируются по названию, но их важность неравномерна — только ~10 характеристик определяют большую часть сигнала. Предполагает возможность выбора характеристик или уменьшения размерности без значительных потерь.

6. Conclusion

Ансамбли > Линейные модели: HistGradientBoosting значительно превосходит логистическую регрессию, подтверждая ценность нелинейного моделирования даже с табличными данными.  
Gradient Boosting превосходит при дисбалансе: несмотря на отсутствие явного перебалансирования, HGB достигает высокой точности обнаружения меньшинств благодаря встроенной регуляризации и контролю глубины.  
ROC-AUC является подходящим: учитывая крайний дисбаланс (~5% положительных), ROC-AUC дает больше информации, чем только точность или F1.  
Стабильность имеет значение: повторные запуски подтверждают, что модели с наилучшими показателями обобщаются по разбиениям данных, что необходимо для надежного машинного обучения.  
Возможна интерпретируемость: даже с моделями «черного ящика» важность перестановки выявляет небольшой поднабор предиктивных характеристик, что помогает в отладке и проверке справедливости.  
Справедливый дизайн протокола: стратифицированное CV, несколько метрик и проверки стабильности формируют ответственный конвейер оценки, который имеет решающее значение для внедрения в реальных условиях.