# HW06 – Report

> Файл: `homeworks/HW06/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (206, 28)
- Целевая переменная: `target` (бинарная: ~70% класс 0, ~30% класс 1)
- Признаки: 25 числовых и 3 категориальных признака

## 2. Protocol

- Разбиение: train/test в соотношении 80/20 с использованием стратификации и `random_state=22`
- Подбор: кросс-валидация на train (5 фолдов, оптимизация метрики AUC)
- Метрики: accuracy, F1, ROC-AUC (метрики подходят для задачи бинарной классификации с несбалансированными классами)

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline с стратегией `most_frequent`)
- LogisticRegression (baseline из S05, использован Pipeline с StandardScaler)
- DecisionTreeClassifier (контроль сложности: `max_depth` и `min_samples_leaf`)
- RandomForestClassifier (подбор гиперпараметров: `max_depth`, `min_samples_leaf`, `max_features`, `n_estimators`)
- GradientBoostingClassifier (один boosting, подбор гиперпараметров: `learning_rate`, `max_depth`, `n_estimators`)

Опционально:

- StackingClassifier (с CV-логикой, базовые модели: Decision Tree и Logistic Regression, мета-модель: Logistic Regression)

## 4. Results

- Таблица финальных метрик на test по всем моделям:
                 Model  Accuracy        F1       AUC
0                Dummy  0.676667  0.000000  0.000000
1  Logistic Regression  0.835000  0.721519  0.886483
2        Decision Tree  0.883750  0.813378  0.919940
3        Random Forest  0.935417  0.894053  0.972918
4    Gradient Boosting  0.945000  0.911290  0.975864
5             Stacking  0.862917  0.770412  0.914308



- Победитель (по ROC-AUC): Gradient Boosting (AUC = 0.9759) - модель показала наилучший результат по основной метрике

## 5. Analysis

- Устойчивость: анализ стабильности результатов при изменении `random_state` проводился для нескольких прогонов (5 запусков для Gradient Boosting и Random Forest), результаты остались стабильными в пределах +/-0.02 по основным метрикам
- Ошибки: confusion matrix для лучшей модели (Gradient Boosting) показала хорошую способность различать классы, с минимальным количеством ложно-положительных и ложно-отрицательных результатов
- Интерпретация: permutation importance для Gradient Boosting (топ-5 признаков): num19, num18, num07, num04, num24 - эти признаки оказывают наибольшее влияние на решение модели

## 6. Conclusion

- Ансамблевые методы (Random Forest, Gradient Boosting) лучше, чем одиночное дерево решений по качеству
- Gradient Boosting показал наилучший результат с AUC=0.97 на тестовой выборке
- Контроль сложности деревьев (ограничение глубины и минимальное количество образцов в листе) помогает избежать переобучения
- Все ансамблевые методы улучшили качество по сравнению с базовой логистической регрессией
- Permutation importance позволил определить наиболее значимые признаки для принятия решений моделью
- Честная оценка: подбор гиперпараметров только на обучающей выборке с помощью кросс-валидации обеспечивает надежность результатов