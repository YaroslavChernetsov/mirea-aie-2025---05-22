# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
S07-hw-dataset-01.csv  
S07-hw-dataset-02.csv  
S07-hw-dataset-03.csv  

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 колонок
- Признаки: числовые (int, float)
- Пропуски: нет
- "Подлости" датасета: разные шкалы, высокая размерность (8 признаков больше чем у двух других датасетов)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 колонки
- Признаки: числовые (int, float)
- Пропуски: нет
- "Подлости" датасета: разные шкалы, выбросы, шум

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 5 колонок
- Признаки: числовые (int, float)
- Пропуски: нет
- "Подлости" датасета: разные шкалы, выбросы, шум, разная плотность

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: Все признаки проходили через StandardScaler
- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k):  
    - Диапазон K для KMeans:   
      kmeans_ks = list(range(2, 21))   
    - Сетка для DBSCAN (eps и min_samples):    
      dbscan_eps = [0.5, 0.8, 1.5, 2.0, 2.5, 3.0, 3.5]   
      dbscan_min_samples = [3, 5, 10]   
    - Agglomerative (число кластеров и linkage):   
      agg_ks = list(range(2, 21))   
      agg_linkages = ["ward", "complete", "average"]   
  - чем руководствовались при выборе "лучшего": silhouette_score
- Метрики: silhouette, Davies-Bouldin, Calinski-Harabasz. Для DBSCAN при наличии шума метрики считались без его учета 
- Визуализация: PCA(2D) 

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

Датасет A
- KMeans (поиск k, фиксировали random_state, n_init)
- DBSCAN (eps, min_samples)
Датасет B
- KMeans (поиск k, фиксировали random_state, n_init)
- DBSCAN (eps, min_samples)
- AgglomerativeClustering (k, linkage)
Датасет C
- KMeans (поиск k, фиксировали random_state, n_init)
- DBSCAN (eps, min_samples)
- AgglomerativeClustering (k, linkage)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: method - kmeans; parametrs: k = 2
- Метрики (silhouette / DB / CH):   
silhouette: 0.522,     
davies_bouldin: 0.685,   
calinski_harabasz: 11786.955   
- Коротко: почему это решение выглядит разумным именно для этого датасета:    
Методы не различались в метриках. Kmeans самый простой, у него был высокий silhouette, он четко разделил кластеры

### 4.2 Dataset B

- Лучший метод и параметры: method - agglomerative; parametrs: k = 2; linkage = average
- Метрики (silhouette / DB / CH):    
silhouette: 0.42,   
davies_bouldin: 0.879,  
calinski_harabasz: 395.483 
- Коротко: почему это решение выглядит разумным именно для этого датасета:   
Agglomerative метод продемонстрировал чуть лучшее значение silhouette_score, чем Kmeans, но все еще не очень высокое. DBSCAN в большинстве конфигураций выявлял один плотный кластер с небольшим числом выбросов, что указывает на отсутствие выраженных плотностных разрывов. AgglomerativeClustering также склонялся к одному доминирующему кластеру. KMeans формально показал сопоставимое значение silhouette, однако визуализация через PCA показывает, что разбиение происходит преимущественно вдоль направления максимальной дисперсии, а не вследствие явной кластерной структуры. Это подтверждает, что данные содержат значительное перекрытие и шум, и задача кластеризации является нетривиальной. Лучшим будем считать метод agglomerative: k = 2; linkage = average

### 4.3 Dataset C

- Лучший метод и параметры: method - agglomerative; k = 2; linkage = average   
- Метрики (silhouette / DB / CH):   
silhouette: 0.425,   
davies_bouldin: 0.814,   
calinski_harabasz: 8.943 
- Коротко: почему это решение выглядит разумным именно для этого датасета:   
Для данного датасета все рассмотренные алгоритмы продемонстрировали ограничения. AgglomerativeClustering показал наибольшее значение silhouette, однако соответствующее разбиение является тривиальным (один доминирующий кластер и небольшой вторичный), что снижает его интерпретируемость.   

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?:   
Kmeas ломается на данных с большим количеством шума и на датасетах, чья форма не похожа на шар, т.к. Kmeans преимущественно разбивает на "шарообразные" кластеры.   
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?:   
DBSCAN и Agglomerative выигрывают на датасетах с шумом и нелинейными связями. DBSCAN сдрадает при слишком большом шуме и разных плотностях датасета.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?:   
Сильнее всего на результат влиял шум, разная плотность, выбросы и наложение точек друг на друга

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход): 5 запусков KMeans по разным seed   
- Что получилось (в 3-6 строк):   
Результаты для каждого из seed оказались идентичны. У всех прогонов ARI и NMI равнялись 1.0. Значения метрик так же оставвались идентичными.   
- Вывод: устойчиво/неустойчиво и почему вы так считаете:   
модель очень устойчивая, т.к. не было замечено никаких изменений в результате при изменении seed.   

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:   
  - профили признаков (средние/медианы) или   
  - любая другая логичная интерпретация   
- 3-6 строк выводов   
Кластеры были интерпретированы на основе геометрии данных и визуализации в пространстве PCA(2D). Разделение в основном происходит вдоль первой главной компоненты, что указывает на доминирующее влияние нескольких признаков с наибольшей дисперсией. При этом внутри кластеров сохраняется существенное перекрытие, что согласуется с умеренными значениями silhouette score. Полученные кластеры отражают скорее глобальную структуру данных, чем чётко разделённые компактные группы.

## 6. Conclusion
## Вывод
В ходе выполнения работы стало ясно, что разные методы кластеризации опираются на разные предположения о структуре данных, и универсального алгоритма, который стабильно давал бы «лучший» результат, не существует. Внутренние метрики качества (silhouette, Davies–Bouldin, Calinski–Harabasz) являются относительными и могут по-разному оценивать одни и те же разбиения, иногда предпочитая тривиальные решения, не отражающие реальную структуру данных. Поэтому выбор «лучшей» модели в unsupervised-задачах нельзя основывать только на максимуме одной метрики - он требует совместного анализа метрик, визуализаций и здравого смысла. Визуализация с помощью PCA помогает проверить адекватность кластеризации, но не является строгим доказательством качества. Отдельно стало очевидно, что корректный протокол эксперимента критически важен: все модели должны сравниваться на одинаково предобработанных данных. В частности, масштабирование признаков является обязательным шагом для distance-based методов, так как различия в шкалах могут полностью исказить результаты кластеризации и значения метрик. Работа показала, что успешная кластеризация требует глубокого понимания данных, критической оценки результатов и готовности признать, что в некоторых случаях внутренняя структура может быть слабо выражена или отсутствовать вовсе.