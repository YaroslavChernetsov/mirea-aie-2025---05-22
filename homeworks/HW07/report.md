# HW07 – Report
> Файл: `homeworks/HW06/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets  
В работе были выбраны 3 синтетических датасета:  
- `S07-hw-dataset-01.csv`  
- `S07-hw-dataset-02.csv`  
- `S07-hw-dataset-03.csv`

### 1.1 Dataset A  
**Файл**: `S07-hw-dataset-01.csv`  
**Размер**: 12 000 объектов, 8 числовых признаков (без учёта `sample_id`)  
**Признаки**: все признаки числовые  
**Пропуски**: отсутствуют  
**"Подлости" датасета**: признаки находятся в разных шкалах, присутствуют шумовые признаки

### 1.2 Dataset B  
**Файл**: `S07-hw-dataset-02.csv`  
**Размер**: 8 000 объектов, 3 числовых признака (без учёта `sample_id`)  
**Признаки**: все признаки числовые  
**Пропуски**: отсутствуют  
**"Подлости" датасета**: нелинейная структура данных, наличие выбросов и шумового признака

### 1.3 Dataset C  
**Файл**: `S07-hw-dataset-03.csv`  
**Размер**: 15 000 объектов, 4 числовых признака (без учёта `sample_id`)  
**Признаки**: все признаки числовые  
**Пропуски**: отсутствуют  
**"Подлости" датасета**: кластеры разной плотности и наличие фонового шума

---

## 2. Protocol  
Для всех датасетов использовался единый и честный unsupervised-протокол.

### Препроцессинг:
- Колонка `sample_id` исключалась из признаков и сохранялась отдельно;
- Числовые признаки обрабатывались с помощью `StandardScaler`;
- Пропуски (если бы они присутствовали) обрабатывались бы через `SimpleImputer`;
- PCA применялся только для визуализации, а не для обучения моделей.

### Поиск гиперпараметров:
- Для **KMeans** перебиралось число кластеров `k` в диапазоне от 2 до 20;
- Фиксировались `random_state=42` и `n_init=10`;
- Для **DBSCAN** подбирался параметр `eps` в диапазоне от 0.1 до 5.0 при фиксированном `min_samples=5`;
- Для **AgglomerativeClustering** перебиралось `k` от 2 до 20 и сравнивались стратегии `linkage='ward'` и `'average'`;
- Лучший вариант выбирался на основе внутренних метрик кластеризации.

### Метрики:
- `silhouette_score`
- `davies_bouldin_score`
- `calinski_harabasz_score`
- Для DBSCAN дополнительно учитывалась доля шума (`label = -1`), а метрики считались только по non-noise объектам.

### Визуализация:
- PCA(2D) scatter с раскраской по полученным кластерам для лучшего решения;
- Графики подбора параметров (например, silhouette vs k или silhouette vs eps).

---

## 3. Models  
Для каждого датасета сравнивались следующие модели:

- **KMeans**: подбирался параметр `k`, фиксировались `random_state` и `n_init`.
- **DBSCAN**: подбирался параметр `eps` (при `min_samples=5`), анализировалась доля шума.
- **AgglomerativeClustering**: подбиралось число кластеров `k`, сравнивались варианты `linkage`.

Таким образом, для каждого датасета рассматривалось три алгоритма кластеризации.

---

## 4. Results  

### 4.1 Dataset A  
**Лучший метод и параметры**: **KMeans**, `k = 2`  
**Метрики**: высокое значение silhouette, низкий Davies–Bouldin  
**Комментарий**: после масштабирования данные формируют чётко разделённые кластеры, что хорошо соответствует предположениям KMeans.

### 4.2 Dataset B  
**Лучший метод и параметры**: **Agglomerative Clustering**, `k = 2`, `linkage = 'average'`  
**Метрики**: silhouette выше, чем у KMeans и DBSCAN  
**Комментарий**: несмотря на нелинейную структуру и выбросы, Agglomerative Clustering показал наилучшее качество по silhouette. DBSCAN не стал победителем, хотя лучше справляется с формой и шумом — его silhouette оказался ниже.

### 4.3 Dataset C  
**Лучший метод и параметры**: **Agglomerative Clustering**, `k = 2`, `linkage = 'average'`  
**Метрики**: silhouette выше, чем у KMeans и DBSCAN  
**Комментарий**: несмотря на разную плотность кластеров и шум, Agglomerative Clustering дал наиболее сбалансированное разбиение. DBSCAN показал высокую долю шума и более низкий silhouette.

---

## 5. Analysis  

### 5.1 Сравнение алгоритмов (важные наблюдения)
- **KMeans** хорошо работает на компактных и примерно сферических кластерах, но чувствителен к выбросам и нарушению предположений о форме кластеров.
- **DBSCAN** выигрывает на данных с шумом и кластерами сложной формы, но чувствителен к выбору параметра `eps` и может терять кластеры низкой плотности.
- **Agglomerative Clustering** продемонстрировал высокую устойчивость к шуму и нелинейной структуре, особенно при использовании `linkage='average'`.
- **Масштабирование признаков** является критически важным шагом для всех алгоритмов, основанных на расстояниях.

### 5.2 Устойчивость (обязательно для одного датасета)  
Для **Dataset A** была проведена проверка устойчивости KMeans: алгоритм запускался 5 раз с различными значениями `random_state`. Сравнение разбиений с помощью Adjusted Rand Index показало **ARI = 1.0** для всех пар запусков.  
Это свидетельствует о полной воспроизводимости кластеризации и наличии устойчивой кластерной структуры в данных.

### 5.3 Интерпретация кластеров  
Кластеры интерпретировались через анализ распределений и средних значений признаков внутри кластеров. В большинстве случаев удалось выделить группы объектов с различающимися масштабами и комбинациями числовых признаков.  
Полученные кластеры являются интерпретируемыми и согласуются с визуализацией в пространстве первых двух компонент PCA.

---

## 6. Conclusion  
- Кластеризация чувствительна к масштабу признаков и требует аккуратного препроцессинга.
- **KMeans** эффективен на простых структурах, но плохо справляется с выбросами и шумом.
- **DBSCAN** лучше подходит для данных с шумом и кластерами сложной формы, но может проигрывать по silhouette при высокой доле шума.
- **Agglomerative Clustering** оказался наиболее универсальным и стабильным методом в условиях данного задания.
- Внутренние метрики (silhouette, Davies–Bouldin, Calinski–Harabasz) дополняют друг друга и должны рассматриваться совместно.
- PCA полезна для визуализации, но не является доказательством качества кластеризации.
- Проверка устойчивости позволяет выявить, является ли полученное разбиение воспроизводимым.
